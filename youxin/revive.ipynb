{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pymssql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-74a8eefc6691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myouxin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;31m#如果不存在一级页面的url，则更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linklist.xls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-74a8eefc6691>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0myouxin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymssql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'localhost:1433'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'car'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'root'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'car_info'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcharset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautocommit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m###　这边是数据库设置，需要修改\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pymssql' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import os, time, random\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process,Queue\n",
    "# import pymssql\n",
    "import sqlite3\n",
    "\n",
    "class youxin:\n",
    "    def __init__(self):\n",
    "        self.conn = pymssql.connect(host='localhost:1433', user='car', password='root', database='car_info',charset='utf8', autocommit=True)  ###　这边是数据库设置，需要修改\n",
    "        \n",
    "        self.driver = self.__class__.getdriver(self)\n",
    "    def getdriver(self):\n",
    "        option = webdriver.ChromeOptions()\n",
    "        #option.add_argument('--headless')\n",
    "        option.add_argument('disable-infobars')\n",
    "        driver = webdriver.Chrome(r'D:\\chromedriver\\chromedriver.exe',chrome_options=option)\n",
    "        driver.maximize_window()\n",
    "        return driver\n",
    "    #把所有的车系页面url保存到文件中\n",
    "    def LinkToExcel(self):\n",
    "        content = requests.get('https://www.xin.com/nanjing/aodi/?channel=a49b117c44837d110753e751863f53').content\n",
    "        soup = BeautifulSoup(content,\"html.parser\")\n",
    "        linklist = []\n",
    "        brandlist = []\n",
    "        #遍历所有车型\n",
    "        for dd in soup.find('ul',attrs={'class':'brand-cars clearfix'}).find_all('dd')[1:]:\n",
    "            link = 'https:'+dd.a['href']\n",
    "            brand = dd.text.strip()\n",
    "            try:\n",
    "                content1 = requests.get(link,timeout=20).content\n",
    "            except:\n",
    "                continue\n",
    "            soup1 = BeautifulSoup(content1,'html.parser')\n",
    "            #遍历所有车系\n",
    "            for i in soup1.find_all('dd',attrs={'data-type':'2'}):\n",
    "                link1 = 'https:'+i.a['href']\n",
    "                print(brand,link1)\n",
    "                #链接\n",
    "                linklist.append(link1)\n",
    "                #车型\n",
    "                brandlist.append(brand)\n",
    "        df = pd.DataFrame()\n",
    "        df['brandlist'] = brandlist\n",
    "        df['linklist'] = linklist\n",
    "        #去重\n",
    "        df.drop_duplicates(['linklist'],keep='last',inplace=True)\n",
    "        #储存到excel文件上面\n",
    "        df.to_excel('linklist.xls',index=False)\n",
    "    #得到浮点数值\n",
    "    def GetFloat(self,x):\n",
    "        try:\n",
    "            return re.findall(r'\\d+\\.\\d+',x)[0]\n",
    "        except:\n",
    "            return ''\n",
    "    def GetInt(self,x):\n",
    "        try:\n",
    "            return re.findall(r'\\d+',x)[0]\n",
    "        except:\n",
    "            return ''\n",
    "    def CarInfoCollection(self):\n",
    "        header = {\n",
    "            'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Encoding':'gzip, deflate, sdch, br',\n",
    "            'Accept-Language':'zh-CN,zh;q=0.8',\n",
    "            'Connection':'keep-alive',\n",
    "            'Cookie':'pif=%7B%22goldNum%22%3A535%2C%22silverNum%22%3A31%2C%22unAuthenNum%22%3A0%7D; RELEASE_KEY=; pif=%7B%22goldNum%22%3A2333%2C%22silverNum%22%3A157%2C%22unAuthenNum%22%3A0%7D; RELEASE_KEY=; XIN_anti_uid=19421D02-7279-B1B9-69D6-801C492B195B; uid=rBAKD1yv/pk4RheDJr+LAg==; XIN_UID_CK=d75c8aea-b53a-d2a5-1a1a-2f19cf7da94a; SEO_REF=https://www.xin.com/nanjing/zhongshun/shiji/; Hm_lvt_ae57612a280420ca44598b857c8a9712=1555037845; Hm_lpvt_ae57612a280420ca44598b857c8a9712=1555041418; XIN_LOCATION_CITY=%7B%22cityid%22%3A%221501%22%2C%22areaid%22%3A%226%22%2C%22big_areaid%22%3A%221%22%2C%22provinceid%22%3A%2215%22%2C%22cityname%22%3A%22%5Cu5357%5Cu4eac%22%2C%22ename%22%3A%22nanjing%22%2C%22shortname%22%3A%22NJ%22%2C%22service%22%3A%221%22%2C%22near%22%3A%221505%2C3001%2C101%2C1507%2C1511%2C2401%2C1502%2C1201%2C1503%2C1518%22%2C%22tianrun_code%22%3A%22025%22%2C%22zhigou%22%3A%221%22%2C%22is_visit%22%3A%221%22%2C%22longitude%22%3A%22118.7968770%22%2C%22latitude%22%3A%2232.0602550%22%2C%22city_rank%22%3A100%2C%22city_group%22%3A%223%22%2C%22is_gold_partner%22%3A%22-1%22%2C%22direct_rent_support%22%3A%221%22%2C%22salvaged_support%22%3A%221%22%2C%22isshow_c%22%3A%221%22%2C%22is_lease_back%22%3A%221%22%2C%22mortgage_service_fee%22%3A%2260000%22%2C%22is_small_pub_house%22%3A%221%22%2C%22is_wz_mortgage%22%3A%220%22%2C%22is_purchase_direct%22%3A%221%22%2C%22is_purchase_origin%22%3A%221%22%2C%22is_ms_ex%22%3A%220%22%2C%22is_ms_trans%22%3A%220%22%2C%22updatetime%22%3A%222019-03-23+22%3A43%3A33%22%2C%22region_name%22%3A%22%5Cu6d77%5Cu68e0%5Cu4e00%5Cu533a%22%2C%22huanxin_id%22%3A%2221070094-f6fa-4b27-9f46-ca906788d940%22%2C%22is_login%22%3A1%7D; NSC_ueyz_yjo_xfc_dpsf=ffffffffaf19140145525d5f4f58455e445a4a423660; session_xin=kc5vb9u4dl73ok882oghmpu2bblr22oi; NSC_my_yjo_xfc_dpsf=ffffffffaf18141e45525d5f4f58455e445a4a423660',\n",
    "            'Host':'www.xin.com',\n",
    "            'Referer':'https://www.xin.com/nanjing/aodi/a4l/i2/',\n",
    "            'Upgrade-Insecure-Requests':'1',\n",
    "            'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "        }\n",
    "        carurl = []\n",
    "        CARMODEL1s = []\n",
    "        ModelYears = []\n",
    "        BRANDs = []\n",
    "        cur = self.conn.cursor()\n",
    "        df = pd.read_excel('linklist.xls')\n",
    "        for index,item in df.iterrows():\n",
    "            link = item[1]\n",
    "            print(link)\n",
    "            BRAND = item[0]\n",
    "            self.driver.get(link)\n",
    "            soup = BeautifulSoup(self.driver.page_source,\"html.parser\")\n",
    "            print('------------')\n",
    "            try:\n",
    "                pagenum = int(soup.find('div',attrs={'class':'con-page search_page_link'}).find_all('a')[-2].text)\n",
    "                print(pagenum)\n",
    "                for num in range(pagenum):\n",
    "                    index = num+1\n",
    "                    pagelink = link+'i{0}/'.format(index)\n",
    "                    try:\n",
    "                        content1 = requests.get(pagelink,headers=header,timeout=25).content\n",
    "                    except:\n",
    "                        continue\n",
    "                    soup1 = BeautifulSoup(content1,\"html.parser\")\n",
    "                    for li in soup1.find_all('li',attrs={'class':'con caritem conHeight'}):\n",
    "                        carlink = 'https:'+li.find('a',attrs={'class':'aimg'})['href']#车辆链接\n",
    "                        carurl.append(carlink)\n",
    "                        CARMODEL1 = li['data-title']#CARMODEL1\n",
    "                        CARMODEL1s.append(CARMODEL1)\n",
    "                        ModelYear = re.findall(r'20\\d+',CARMODEL1)[0]#ModelYear\n",
    "                        ModelYears.append(ModelYear)\n",
    "                        BRANDs.append(BRAND)\n",
    "#                         cur.execute(\"insert into carurl(url) values(%s)\",(carlink))\n",
    "            except Exception as e:\n",
    "                    print(e.args)\n",
    "                    for li in soup.find_all('li',attrs={'class':'con caritem conHeight'}):\n",
    "                        carlink = 'https:'+li.find('a',attrs={'class':'aimg'})['href']#车辆链接\n",
    "                        carurl.append(carlink)\n",
    "                        CARMODEL1 = li['data-title']#CARMODEL1\n",
    "                        CARMODEL1s.append(CARMODEL1)\n",
    "                        ModelYear = re.findall(r'20\\d+',CARMODEL1)[0]#ModelYear\n",
    "                        ModelYears.append(ModelYear)\n",
    "                        BRANDs.append(BRAND)\n",
    "#                         cur.execute(\"insert into carurl(url) values(%s)\",(carlink))\n",
    "        df1 = pd.DataFrame()\n",
    "        df1['url'] = carurl\n",
    "        df1['CARMODEL1'] = CARMODEL1s\n",
    "        df1['ModelYear'] = ModelYears\n",
    "        df1['BRANDs'] = BRANDs\n",
    "        df1.to_csv('carurl.csv',index=False)\n",
    "    def carcollection(self,item):\n",
    "        cur = self.conn.cursor()\n",
    "        carlink = item[0]\n",
    "        n = cur.execute(\"select * from youxin where PageUrl=%s\",(carlink))\n",
    "        if n is not None:\n",
    "            return ''\n",
    "        CARMODEL1 = item[1]\n",
    "        ModelYear = item[2]\n",
    "        BRAND = item[3]\n",
    "        self.driver.get(carlink)\n",
    "        if '优信二手车-人机验证页' in self.driver.title:\n",
    "            print('优信二手车-人机验证页')\n",
    "            self.carcollection(item)\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('//*[@id=\"cd_m_clxx\"]/div[4]').click()\n",
    "        except:\n",
    "            return\n",
    "        jsvar = self.driver.execute_script(\"return jsvar;\")\n",
    "        soup2 = BeautifulSoup(self.driver.page_source,\"html.parser\")\n",
    "        OEM =  soup2.find(text='车辆厂商').findNext('span').text.replace('\\n','').strip()#OEM\n",
    "        print(OEM)\n",
    "        RETAILUC = soup2.find('p',attrs={'class':'cd_m_info_price'}).find('span',attrs={'class':'cd_m_info_jg'}).text.strip()#RETAIL-UC\n",
    "        RETAILUC = self.GetFloat(RETAILUC)\n",
    "        MSRPTAX = soup2.find('p',attrs={'class':'cd_m_info_price'}).find('span',attrs={'class':re.compile('cd_m_info_qgzg')}).text.strip()#MSRPTAX\n",
    "        MSRPTAX = self.GetFloat(MSRPTAX)\n",
    "        PLATEDATE = soup2.find('ul',attrs={'class':'cd_m_info_desc'}).find('span',attrs={'class':'cd_m_desc_key'}).text.strip()#PLATEDATE\n",
    "        PLATEDATE = '-'.join(re.findall(r'\\d+',PLATEDATE))+'-01'\n",
    "        CKEXPDATE = soup2.find(text='年检到期').findNext('span').text#CKEXPDATE\n",
    "        MILEAGE = soup2.find('div',attrs={'class':'cd_m_i_pz'}).find_all('span',attrs={'class':'cd_m_i_pz_val'})[1].text.strip()#MILEAGE\n",
    "        MILEAGE = self.GetFloat(MILEAGE)\n",
    "        WHEELBASE = soup2.find(text='轴距').findNext('span').text\n",
    "        WHEELBASE = self.GetInt(WHEELBASE)#WHEELBASE\n",
    "        FUELECONOMY = soup2.find('span',text=re.compile('综合油耗')).findNext('span').text#FUELECONOMY\n",
    "        FUELECONOMY = self.GetInt(FUELECONOMY)#FUELECONOMY\n",
    "        EMISSION = soup2.find('span',text=re.compile('排放标准')).findNext('span').text\n",
    "        try:\n",
    "            OFFERDATE = jsvar['first_publishtime']\n",
    "        except:\n",
    "            OFFERDATE = ''\n",
    "        IFBUSINESS = soup2.find('span',text=re.compile('使用性质')).findNext('span').text.replace('\\n','').strip()\n",
    "        IFINSURANCE = soup2.find('div',attrs={'class':'cd_m_pop_clxx_right'}).find_all('img')[0]\n",
    "        IFINSURANCE = re.findall(r'\\d+',str(IFINSURANCE))[0]\n",
    "        DRIVETYPE = soup2.find('span',text=re.compile('驱动方式')).findNext('span').text.replace('\\n','').strip()\n",
    "        SMT = soup2.find('span',text=re.compile('保养情况')).findNext('span').text.replace('\\n','').strip()\n",
    "        FUEL = soup2.find('span',text=re.compile('燃油标号')).findNext('span').text.replace('\\n','').strip()\n",
    "        SALESDATE = soup2.find('span',text=re.compile('上市时间')).findNext('span').text.replace('\\n','').strip()\n",
    "        try:\n",
    "            city = jsvar['car_city']['car_cityname']\n",
    "        except:\n",
    "            city = ''\n",
    "        try:\n",
    "            city2 = jsvar['cityname']\n",
    "        except:\n",
    "            city2 = ''\n",
    "        try:\n",
    "            TRANSFERTIMES = jsvar['saletime']\n",
    "        except:\n",
    "            TRANSFERTIMES = ''\n",
    "        try:\n",
    "            DEALER = jsvar['dealername']\n",
    "        except:\n",
    "            DEALER = ''\n",
    "        try:\n",
    "            carid = jsvar['carid']\n",
    "        except:\n",
    "            carid = ''\n",
    "        sql = \"insert into youxin(BRAND,OEM,CARMODEL1,ModelYear,MSRPTAX,RETAILUC,PLATEDATE,CKEXPDATE,MILEAGE,WHEELBASE,FUELECONOMY,EMISSION,OFFERDATE,DATADATE,DEALER,CITY,IFBUSINESS,IFINSURANCE,DRIVETYPE,TRANSFERTIMES,4SMT,FUEL,SALESDATE,CarID,CITY2,PageUrl) values('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s')\"\n",
    "        params = (BRAND,OEM,CARMODEL1,str(ModelYear).replace(\"'\",\"\\\"\"),MSRPTAX,RETAILUC,PLATEDATE,CKEXPDATE,MILEAGE.replace(\"'\",\"\\\"\"),WHEELBASE,FUELECONOMY,EMISSION,OFFERDATE,time.strftime('%Y%m%d'),DEALER,city,IFBUSINESS,IFINSURANCE,DRIVETYPE,TRANSFERTIMES,SMT,FUEL,SALESDATE,carid,city2,carlink)\n",
    "        print(params)\n",
    "        cur.execute(sql,params)\n",
    "def write(q):\n",
    "\tdf = pd.read_csv(\"carurl.csv\")\n",
    "\tdf.drop_duplicates('url',inplace=True)\n",
    "\tfor index,item in df.iterrows():\n",
    "\t\tq.put(item)\n",
    "\t\t#time.sleep(random.random())\n",
    "def read(q):\n",
    "\tprint('读取进程------')\n",
    "\tc = youxin()\n",
    "\twhile(True):\n",
    "\t\tif not q.empty():\n",
    "\t\t\titem = q.get(True)\n",
    "\t\t\tc.carcollection(item)\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    c = youxin()\n",
    "    #如果不存在一级页面的url，则更新\n",
    "    if not os.path.exists('linklist.xls'):\n",
    "        c.LinkToExcel()\n",
    "    #c.CarInfoCollection()\n",
    "    #del c\n",
    "    q = Queue()\n",
    "    pw = Process(target=write,args=(q,))\n",
    "    pr1 = Process(target=read,args=(q,))\n",
    "    pr2 = Process(target=read,args=(q,))\n",
    "    pr3 = Process(target=read,args=(q,))\n",
    "    pw.start()\n",
    "\n",
    "    pr1.start()\n",
    "    pr2.start()\n",
    "    pr3.start()\n",
    "    pw.join()\n",
    "    pr1.join()\n",
    "    pr2.join()\n",
    "    pr3.join()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: - ^C\n",
      "failed\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"insert into youxin(BRAND,OEM,CARMODEL1,ModelYear,MSRPTAX,RETAILUC,PLATEDATE,CKEXPDATE,MILEAGE,WHEELBASE,FUELECONOMY,EMISSION,OFFERDATE,DATADATE,DEALER,CITY,IFBUSINESS,IFINSURANCE,DRIVETYPE,TRANSFERTIMES,4SMT,FUEL,SALESDATE,CarID,CITY2,PageUrl) values('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s')\"\n",
    "params = ('奥迪', '一汽-大众奥迪', '奥迪 A3两厢 2014款 1.4T 自动 35TFSI进取型', '2014', '13.28', '12.41', '2014-09-01', '2020-09-01', '5.1', '2629', '5', '国5', '2019-04-04T11:44:44Z', '20190423', '石家庄瑞诚安丽精品车行（2队）', '石家庄', '非营运', '201512', '前驱', '0', '无', '97(京95)', '2014-03-20', '57288770', '南京', 'https://www.xin.com/40d0jyywy9/che57288770.html?cityid=1501')\n",
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
